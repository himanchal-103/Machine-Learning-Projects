{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTING NECESSARY LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "import syllapy\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STOPWORDS AND PUNCTUATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "# stopwords \n",
    "stop = stopwords.words('english')\n",
    "print(stop)\n",
    "\n",
    "# punctuations\n",
    "punctuations = list(string.punctuation)\n",
    "print(punctuations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StopWords_Names.txt', 'StopWords_Auditor.txt', 'StopWords_Geographic.txt', 'StopWords_Generic.txt', 'StopWords_Currencies.txt', 'StopWords_DatesandNumbers.txt', 'StopWords_GenericLong.txt']\n"
     ]
    }
   ],
   "source": [
    "# getting list of files in StopWords directory\n",
    "files = os.listdir('Input_data/StopWords')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------path :  Input_data/StopWords/StopWords_Names.txt\n",
      "13014\n",
      "----------path :  Input_data/StopWords/StopWords_Auditor.txt\n",
      "8\n",
      "----------path :  Input_data/StopWords/StopWords_Geographic.txt\n",
      "199\n",
      "----------path :  Input_data/StopWords/StopWords_Generic.txt\n",
      "121\n",
      "----------path :  Input_data/StopWords/StopWords_Currencies.txt\n",
      "85\n",
      "----------path :  Input_data/StopWords/StopWords_DatesandNumbers.txt\n",
      "109\n",
      "----------path :  Input_data/StopWords/StopWords_GenericLong.txt\n",
      "571\n",
      "length of stopwords :  14107\n"
     ]
    }
   ],
   "source": [
    "stopwords = []\n",
    "for file in files:\n",
    "    path = 'Input_data/StopWords/' + file\n",
    "    print('----------path : ', path)\n",
    "    try:\n",
    "        with open(path, 'r', encoding='UTF-8') as f:\n",
    "            words = f.readlines()\n",
    "            print(len(words))\n",
    "            for i in words:\n",
    "                stopwords.append(i.split()[0].strip('\\n').lower())\n",
    "        \n",
    "    except UnicodeDecodeError:  # for file StopWords_Currencies.txt\n",
    "        with open(path, 'r', encoding='latin-1') as f:\n",
    "            words = f.readlines()\n",
    "            print(len(words))\n",
    "            for i in words:\n",
    "                stopwords.append(i.split('|')[0].strip().lower())\n",
    "\n",
    "print('length of stopwords : ', len(stopwords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14318\n"
     ]
    }
   ],
   "source": [
    "stopwords = stopwords + stop + punctuations\n",
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MASTERDICTIONARY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive-words.txt', 'negative-words.txt']\n"
     ]
    }
   ],
   "source": [
    "# list of files in MasterDictionary directory\n",
    "files = os.listdir('Input_data/MasterDictionary')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of positive words :  2006\n",
      "num of negative words :  4783\n"
     ]
    }
   ],
   "source": [
    "positive_words, negative_words = [], []\n",
    "\n",
    "path = 'Input_data/MasterDictionary/positive-words.txt'\n",
    "with open(path, 'r', encoding='latin-1') as f:\n",
    "    words = f.readlines()\n",
    "    for i in words:\n",
    "        positive_words.append(i.rstrip('\\n').lower())\n",
    "print('num of positive words : ', len(positive_words))\n",
    "\n",
    "\n",
    "path = 'Input_data/MasterDictionary/negative-words.txt'\n",
    "with open(path, 'r', encoding='latin-1') as f:\n",
    "    words = f.readlines()\n",
    "    for i in words:\n",
    "        negative_words.append(i.rstrip('\\n').lower())\n",
    "print('num of negative words : ', len(negative_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords ---> contains list of stopwords from nltk library, punctuations, and stopwords provided\n",
    "# positive_words ---> contains list of positive words\n",
    "# negative_words ---> contains list of negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean words\n",
    "def clean(words):\n",
    "    clean_word = [w for w in words if not w.lower() in stopwords]\n",
    "    return clean_word\n",
    "\n",
    "\n",
    "# function to calculate positive score, negative score, polarity score and subjectivity score\n",
    "def sentimental_analysis(clean_word):\n",
    "    result = []\n",
    "    positive_score, negative_score = 0, 0\n",
    "\n",
    "    for i in clean_word:\n",
    "        if i.lower() in positive_words:\n",
    "            positive_score += 1\n",
    "        elif i.lower() in negative_words:\n",
    "            negative_score += 1\n",
    "\n",
    "    result.append(positive_score)\n",
    "    result.append(negative_score)\n",
    "\n",
    "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "    subjectivity_score = (positive_score + negative_score) / ((len(clean_word)) + 0.000001)\n",
    "\n",
    "    result.append(polarity_score)\n",
    "    result.append(subjectivity_score)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# function to count syllables\n",
    "def count_syllables(word):     \n",
    "    return syllapy.count(word)\n",
    "\n",
    "\n",
    "# function to count complex word\n",
    "def count_complex_words(words):\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        n = count_syllables(word.lower())\n",
    "        if n > 2:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "# function for readability analysis (average sentence length, percentage of complex words, and fog index)\n",
    "def readability(words, sentences, cnt_complex_word):\n",
    "    avg_sentence_len = len(words) / len(sentences)\n",
    "    percent_complex_word = cnt_complex_word / len(words)\n",
    "    fog_index = 0.4 * (avg_sentence_len + percent_complex_word)\n",
    "\n",
    "    return [avg_sentence_len, percent_complex_word, fog_index]\n",
    "\n",
    "\n",
    "# funtion to count total syllables\n",
    "def count_total_syllable(words):\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        cnt = count_syllables(word.lower())\n",
    "        count += cnt\n",
    "    return count\n",
    "\n",
    "\n",
    "# function to count personal pronouns\n",
    "def count_personal_pronouns(text):\n",
    "    pattern = r'\\b(I|we|my|ours|us)\\b'\n",
    "    regex = re.compile(pattern, flags=re.IGNORECASE)\n",
    "    matches = regex.findall(text)\n",
    "    count = len(matches)\n",
    "    return count\n",
    "\n",
    "\n",
    "# function to calculate average word length\n",
    "def calculate_avg_word_length(words):\n",
    "    cnt = 0\n",
    "    for word in words:\n",
    "        cnt += len(word)\n",
    "    \n",
    "    return cnt / len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FOR ONE FILE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rising IT cities and its impact on the economy, environment, infrastructure, and city life by the year 2040. We have seen a huge development and dependence of people on technology in recent years. We have also seen the development of AI and ChatGPT in recent years. So it is a normal thing that we will become fully dependent on technology by 2040. Information technology will be a major power for all the developing nations. As a member of a developing nation, India is rapidly growing its IT base. It has also grown some IT cities which will be the major control centres for Information technology by 2040. Rising IT cities Kolkata:- Kolkata in West Bengal is an emerging major IT hub. The new Kolkata i.e. Saltlake Sector  5, New town, Rajarhat area of Kolkata is a major IT hub. The government is giving the software companies land at almost free of cost to set up the companies there. Many large companies like Google, Microsoft, IBM, Infosys and others have set up their companies here. Kolkata has a market base of billions of dollars and is doing a great job of boosting the national economy. Impact on Economy There is a huge impact of the rising IT cities on our economy. Some of the effects are- Impact on Environment The rising IT cities will create a huge impact on the environment, the maximum of which will be harmful effects. The impact of rising IT cities on the environment is- Impact on infrastructure There are many contributions of the IT cities on infrastructure.  They are- Impact on city life With the growth of IT cities, more people will get jobs and will earn more. So the purchasing power of the people will increase. People will lead a better lifestyle. They will buy things of good brand value. The tastes and preferences of people will also change. The human development index is going to increase. People will buy good quality food and good quality cars. So the food, automobile and many other industries are going to increase. So there will be a huge impact on city life by 2040.\n"
     ]
    }
   ],
   "source": [
    "# access the data scrapped\n",
    "path = 'Text_File/' + 'blackassign0001.txt'\n",
    "with open(path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content[0] = content[0].rstrip('\\n')\n",
    "    # print(content)\n",
    "    text = ' '.join(content)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rising IT cities and its impact on the economy, environment, infrastructure, and city life by the year 2040.', 'We have seen a huge development and dependence of people on technology in recent years.', 'We have also seen the development of AI and ChatGPT in recent years.', 'So it is a normal thing that we will become fully dependent on technology by 2040.', 'Information technology will be a major power for all the developing nations.', 'As a member of a developing nation, India is rapidly growing its IT base.', 'It has also grown some IT cities which will be the major control centres for Information technology by 2040.', 'Rising IT cities Kolkata:- Kolkata in West Bengal is an emerging major IT hub.', 'The new Kolkata i.e.', 'Saltlake Sector\\xa0 5, New town, Rajarhat area of Kolkata is a major IT hub.', 'The government is giving the software companies land at almost free of cost to set up the companies there.', 'Many large companies like Google, Microsoft, IBM, Infosys and others have set up their companies here.', 'Kolkata has a market base of billions of dollars and is doing a great job of boosting the national economy.', 'Impact on Economy There is a huge impact of the rising IT cities on our economy.', 'Some of the effects are- Impact on Environment The rising IT cities will create a huge impact on the environment, the maximum of which will be harmful effects.', 'The impact of rising IT cities on the environment is- Impact on infrastructure There are many contributions of the IT cities on infrastructure.', 'They are- Impact on city life With the growth of IT cities, more people will get jobs and will earn more.', 'So the purchasing power of the people will increase.', 'People will lead a better lifestyle.', 'They will buy things of good brand value.', 'The tastes and preferences of people will also change.', 'The human development index is going to increase.', 'People will buy good quality food and good quality cars.', 'So the food, automobile and many other industries are going to increase.', 'So there will be a huge impact on city life by 2040.'] \n",
      " 25\n",
      "['Rising', 'IT', 'cities', 'and', 'its', 'impact', 'on', 'the', 'economy', ',', 'environment', ',', 'infrastructure', ',', 'and', 'city', 'life', 'by', 'the', 'year', '2040', '.', 'We', 'have', 'seen', 'a', 'huge', 'development', 'and', 'dependence', 'of', 'people', 'on', 'technology', 'in', 'recent', 'years', '.', 'We', 'have', 'also', 'seen', 'the', 'development', 'of', 'AI', 'and', 'ChatGPT', 'in', 'recent', 'years', '.', 'So', 'it', 'is', 'a', 'normal', 'thing', 'that', 'we', 'will', 'become', 'fully', 'dependent', 'on', 'technology', 'by', '2040', '.', 'Information', 'technology', 'will', 'be', 'a', 'major', 'power', 'for', 'all', 'the', 'developing', 'nations', '.', 'As', 'a', 'member', 'of', 'a', 'developing', 'nation', ',', 'India', 'is', 'rapidly', 'growing', 'its', 'IT', 'base', '.', 'It', 'has', 'also', 'grown', 'some', 'IT', 'cities', 'which', 'will', 'be', 'the', 'major', 'control', 'centres', 'for', 'Information', 'technology', 'by', '2040', '.', 'Rising', 'IT', 'cities', 'Kolkata', ':', '-', 'Kolkata', 'in', 'West', 'Bengal', 'is', 'an', 'emerging', 'major', 'IT', 'hub', '.', 'The', 'new', 'Kolkata', 'i.e', '.', 'Saltlake', 'Sector', '5', ',', 'New', 'town', ',', 'Rajarhat', 'area', 'of', 'Kolkata', 'is', 'a', 'major', 'IT', 'hub', '.', 'The', 'government', 'is', 'giving', 'the', 'software', 'companies', 'land', 'at', 'almost', 'free', 'of', 'cost', 'to', 'set', 'up', 'the', 'companies', 'there', '.', 'Many', 'large', 'companies', 'like', 'Google', ',', 'Microsoft', ',', 'IBM', ',', 'Infosys', 'and', 'others', 'have', 'set', 'up', 'their', 'companies', 'here', '.', 'Kolkata', 'has', 'a', 'market', 'base', 'of', 'billions', 'of', 'dollars', 'and', 'is', 'doing', 'a', 'great', 'job', 'of', 'boosting', 'the', 'national', 'economy', '.', 'Impact', 'on', 'Economy', 'There', 'is', 'a', 'huge', 'impact', 'of', 'the', 'rising', 'IT', 'cities', 'on', 'our', 'economy', '.', 'Some', 'of', 'the', 'effects', 'are-', 'Impact', 'on', 'Environment', 'The', 'rising', 'IT', 'cities', 'will', 'create', 'a', 'huge', 'impact', 'on', 'the', 'environment', ',', 'the', 'maximum', 'of', 'which', 'will', 'be', 'harmful', 'effects', '.', 'The', 'impact', 'of', 'rising', 'IT', 'cities', 'on', 'the', 'environment', 'is-', 'Impact', 'on', 'infrastructure', 'There', 'are', 'many', 'contributions', 'of', 'the', 'IT', 'cities', 'on', 'infrastructure', '.', 'They', 'are-', 'Impact', 'on', 'city', 'life', 'With', 'the', 'growth', 'of', 'IT', 'cities', ',', 'more', 'people', 'will', 'get', 'jobs', 'and', 'will', 'earn', 'more', '.', 'So', 'the', 'purchasing', 'power', 'of', 'the', 'people', 'will', 'increase', '.', 'People', 'will', 'lead', 'a', 'better', 'lifestyle', '.', 'They', 'will', 'buy', 'things', 'of', 'good', 'brand', 'value', '.', 'The', 'tastes', 'and', 'preferences', 'of', 'people', 'will', 'also', 'change', '.', 'The', 'human', 'development', 'index', 'is', 'going', 'to', 'increase', '.', 'People', 'will', 'buy', 'good', 'quality', 'food', 'and', 'good', 'quality', 'cars', '.', 'So', 'the', 'food', ',', 'automobile', 'and', 'many', 'other', 'industries', 'are', 'going', 'to', 'increase', '.', 'So', 'there', 'will', 'be', 'a', 'huge', 'impact', 'on', 'city', 'life', 'by', '2040', '.'] \n",
      " 395\n"
     ]
    }
   ],
   "source": [
    "token_sent = sent_tokenize(text)\n",
    "token_word = word_tokenize(text)\n",
    "print(token_sent, '\\n', len(token_sent))\n",
    "print(token_word, '\\n', len(token_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_word :  149\n",
      "['Rising', 'cities', 'impact', 'economy', 'environment', 'infrastructure', 'life', '2040', 'huge', 'development', 'dependence', 'people', 'technology', 'recent', 'years', 'development', 'ChatGPT', 'recent', 'years', 'normal', 'thing', 'fully', 'dependent', 'technology', '2040', 'Information', 'technology', 'developing', 'member', 'developing', 'rapidly', 'growing', 'base', 'grown', 'cities', 'control', 'centres', 'Information', 'technology', '2040', 'Rising', 'cities', 'Kolkata', 'Kolkata', 'Bengal', 'emerging', 'hub', 'Kolkata', 'i.e', 'Saltlake', 'Sector', '5', 'town', 'Rajarhat', 'area', 'Kolkata', 'hub', 'government', 'giving', 'software', 'companies', 'cost', 'set', 'companies', 'companies', 'Google', 'Microsoft', 'IBM', 'Infosys', 'set', 'companies', 'Kolkata', 'market', 'base', 'billions', 'dollars', 'great', 'job', 'boosting', 'national', 'economy', 'Impact', 'Economy', 'huge', 'impact', 'rising', 'cities', 'economy', 'effects', 'are-', 'Impact', 'Environment', 'rising', 'cities', 'create', 'huge', 'impact', 'environment', 'maximum', 'harmful', 'effects', 'impact', 'rising', 'cities', 'environment', 'is-', 'Impact', 'infrastructure', 'contributions', 'cities', 'infrastructure', 'are-', 'Impact', 'life', 'growth', 'cities', 'people', 'jobs', 'earn', 'purchasing', 'people', 'increase', 'People', 'lead', 'lifestyle', 'buy', 'things', 'tastes', 'preferences', 'people', 'change', 'human', 'development', 'index', 'increase', 'People', 'buy', 'quality', 'food', 'quality', 'cars', 'food', 'automobile', 'industries', 'increase', 'huge', 'impact', 'life', '2040']\n"
     ]
    }
   ],
   "source": [
    "# removing stop words from token words\n",
    "# clean_word = [w for w in token_word if not w.lower() in stopwords]\n",
    "clean_word = clean(token_word)\n",
    "print('clean_word : ', len(clean_word))\n",
    "print(clean_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 0.33333322222225925, 0.020134228052790415]\n"
     ]
    }
   ],
   "source": [
    "# calculate positive score, negative score, polarity score and subjectivity score\n",
    "score = sentimental_analysis(clean_word)\n",
    "print(score)\n",
    "\n",
    "POSITIVE_SCORE = score[0]\n",
    "NEGATIVE_SCORE = score[1]\n",
    "POLARITY_SCORE = score[2]\n",
    "SUBJECTIVITY_SCORE = score[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "# counting number of complex words\n",
    "COMPLEX_WORDS = count_complex_words(clean_word)\n",
    "print(COMPLEX_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.96, 0.3221476510067114, 2.512859060402685]\n"
     ]
    }
   ],
   "source": [
    "# Average Sentence Length = the number of words / the number of sentences\n",
    "# Percentage of Complex words = the number of complex words / the number of words \n",
    "# Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n",
    "\n",
    "# calculating average sentence length, percentage of complex words, and fog index\n",
    "results = readability(clean_word, token_sent, COMPLEX_WORDS)\n",
    "print(results)\n",
    "\n",
    "AVERAGE_SENTENCE_LENGTH = results[0]\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = results[1]\n",
    "FOG_INDEX = results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.8\n"
     ]
    }
   ],
   "source": [
    "# Average Number of Words Per Sentence = the total number of words / the total number of sentences\n",
    "AVERAGE_NUMBER_OF_WORDS_PER_SENTENCE = len(token_word) / len(token_sent)\n",
    "print(AVERAGE_NUMBER_OF_WORDS_PER_SENTENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "# word count is total cleaned words present in the text \n",
    "WORD_COUNT = len(clean_word)\n",
    "print(WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n"
     ]
    }
   ],
   "source": [
    "# counting number of syllables\n",
    "SYLLABLE_COUNT_PER_WORD = count_total_syllable(clean_word)\n",
    "print(SYLLABLE_COUNT_PER_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# calculating personal pronouns\n",
    "PERSONAL_PRONOUNS = count_personal_pronouns(text)\n",
    "print(PERSONAL_PRONOUNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.651006711409396\n"
     ]
    }
   ],
   "source": [
    "# calculating average word length\n",
    "AVERAGE_WORD_LENGTH = calculate_avg_word_length(clean_word)\n",
    "print(AVERAGE_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FOR ALL TEXT FILES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['blackassign0001', 'blackassign0002', 'blackassign0003', 'blackassign0004', 'blackassign0005', 'blackassign0006', 'blackassign0007', 'blackassign0008', 'blackassign0009', 'blackassign0010', 'blackassign0011', 'blackassign0012', 'blackassign0013', 'blackassign0014', 'blackassign0015', 'blackassign0016', 'blackassign0017', 'blackassign0018', 'blackassign0019', 'blackassign0020', 'blackassign0021', 'blackassign0022', 'blackassign0023', 'blackassign0024', 'blackassign0025', 'blackassign0026', 'blackassign0027', 'blackassign0028', 'blackassign0029', 'blackassign0030', 'blackassign0031', 'blackassign0032', 'blackassign0033', 'blackassign0034', 'blackassign0035', 'blackassign0036', 'blackassign0037', 'blackassign0038', 'blackassign0039', 'blackassign0040', 'blackassign0041', 'blackassign0042', 'blackassign0043', 'blackassign0044', 'blackassign0045', 'blackassign0046', 'blackassign0047', 'blackassign0048', 'blackassign0049', 'blackassign0050', 'blackassign0051', 'blackassign0052', 'blackassign0053', 'blackassign0054', 'blackassign0055', 'blackassign0056', 'blackassign0057', 'blackassign0058', 'blackassign0059', 'blackassign0060', 'blackassign0061', 'blackassign0062', 'blackassign0063', 'blackassign0064', 'blackassign0065', 'blackassign0066', 'blackassign0067', 'blackassign0068', 'blackassign0069', 'blackassign0070', 'blackassign0071', 'blackassign0072', 'blackassign0073', 'blackassign0074', 'blackassign0075', 'blackassign0076', 'blackassign0077', 'blackassign0078', 'blackassign0079', 'blackassign0080', 'blackassign0081', 'blackassign0082', 'blackassign0083', 'blackassign0084', 'blackassign0085', 'blackassign0086', 'blackassign0087', 'blackassign0088', 'blackassign0089', 'blackassign0090', 'blackassign0091', 'blackassign0092', 'blackassign0093', 'blackassign0094', 'blackassign0095', 'blackassign0096', 'blackassign0097', 'blackassign0098', 'blackassign0099', 'blackassign0100']\n",
      "100 ['https://insights.blackcoffer.com/rising-it-cities-and-its-impact-on-the-economy-environment-infrastructure-and-city-life-by-the-year-2040-2/', 'https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/', 'https://insights.blackcoffer.com/internet-demands-evolution-communication-impact-and-2035s-alternative-pathways/', 'https://insights.blackcoffer.com/rise-of-cybercrime-and-its-effect-in-upcoming-future/', 'https://insights.blackcoffer.com/ott-platform-and-its-impact-on-the-entertainment-industry-in-future/', 'https://insights.blackcoffer.com/the-rise-of-the-ott-platform-and-its-impact-on-the-entertainment-industry-by-2040/', 'https://insights.blackcoffer.com/rise-of-cyber-crime-and-its-effects/', 'https://insights.blackcoffer.com/rise-of-internet-demand-and-its-impact-on-communications-and-alternatives-by-the-year-2035-2/', 'https://insights.blackcoffer.com/rise-of-cybercrime-and-its-effect-by-the-year-2040-2/', 'https://insights.blackcoffer.com/rise-of-cybercrime-and-its-effect-by-the-year-2040/', 'https://insights.blackcoffer.com/rise-of-internet-demand-and-its-impact-on-communications-and-alternatives-by-the-year-2035/', 'https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-3-2/', 'https://insights.blackcoffer.com/rise-of-e-health-and-its-impact-on-humans-by-the-year-2030/', 'https://insights.blackcoffer.com/rise-of-e-health-and-its-imapct-on-humans-by-the-year-2030-2/', 'https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-2/', 'https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-2-2/', 'https://insights.blackcoffer.com/rise-of-chatbots-and-its-impact-on-customer-support-by-the-year-2040/', 'https://insights.blackcoffer.com/rise-of-e-health-and-its-imapct-on-humans-by-the-year-2030/', 'https://insights.blackcoffer.com/how-does-marketing-influence-businesses-and-consumers/', 'https://insights.blackcoffer.com/how-advertisement-increase-your-market-value/', 'https://insights.blackcoffer.com/negative-effects-of-marketing-on-society/', 'https://insights.blackcoffer.com/how-advertisement-marketing-affects-business/', 'https://insights.blackcoffer.com/rising-it-cities-will-impact-the-economy-environment-infrastructure-and-city-life-by-the-year-2035/', 'https://insights.blackcoffer.com/rise-of-ott-platform-and-its-impact-on-entertainment-industry-by-the-year-2030/', 'https://insights.blackcoffer.com/rise-of-electric-vehicles-and-its-impact-on-livelihood-by-2040/', 'https://insights.blackcoffer.com/rise-of-electric-vehicle-and-its-impact-on-livelihood-by-the-year-2040/', 'https://insights.blackcoffer.com/oil-prices-by-the-year-2040-and-how-it-will-impact-the-world-economy/', 'https://insights.blackcoffer.com/an-outlook-of-healthcare-by-the-year-2040-and-how-it-will-impact-human-lives/', 'https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/', 'https://insights.blackcoffer.com/what-if-the-creation-is-taking-over-the-creator/', 'https://insights.blackcoffer.com/what-jobs-will-robots-take-from-humans-in-the-future/', 'https://insights.blackcoffer.com/will-machine-replace-the-human-in-the-future-of-work/', 'https://insights.blackcoffer.com/will-ai-replace-us-or-work-with-us/', 'https://insights.blackcoffer.com/man-and-machines-together-machines-are-more-diligent-than-humans-blackcoffe/', 'https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/', 'https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/', 'https://insights.blackcoffer.com/how-machine-learning-will-affect-your-business/', 'https://insights.blackcoffer.com/deep-learning-impact-on-areas-of-e-learning/', 'https://insights.blackcoffer.com/how-to-protect-future-data-and-its-privacy-blackcoffer/', 'https://insights.blackcoffer.com/how-machines-ai-automations-and-robo-human-are-effective-in-finance-and-banking/', 'https://insights.blackcoffer.com/ai-human-robotics-machine-future-planet-blackcoffer-thinking-jobs-workplace/', 'https://insights.blackcoffer.com/how-ai-will-change-the-world-blackcoffer/', 'https://insights.blackcoffer.com/future-of-work-how-ai-has-entered-the-workplace/', 'https://insights.blackcoffer.com/ai-tool-alexa-google-assistant-finance-banking-tool-future/', 'https://insights.blackcoffer.com/ai-healthcare-revolution-ml-technology-algorithm-google-analytics-industrialrevolution/', 'https://insights.blackcoffer.com/all-you-need-to-know-about-online-marketing/', 'https://insights.blackcoffer.com/evolution-of-advertising-industry/', 'https://insights.blackcoffer.com/how-data-analytics-can-help-your-business-respond-to-the-impact-of-covid-19/', 'https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/', 'https://insights.blackcoffer.com/environmental-impact-of-the-covid-19-pandemic-lesson-for-the-future/', 'https://insights.blackcoffer.com/how-data-analytics-and-ai-are-used-to-halt-the-covid-19-pandemic/', 'https://insights.blackcoffer.com/difference-between-artificial-intelligence-machine-learning-statistics-and-data-mining/', 'https://insights.blackcoffer.com/how-python-became-the-first-choice-for-data-science/', 'https://insights.blackcoffer.com/how-google-fit-measure-heart-and-respiratory-rates-using-a-phone/', 'https://insights.blackcoffer.com/what-is-the-future-of-mobile-apps/', 'https://insights.blackcoffer.com/impact-of-ai-in-health-and-medicine/', 'https://insights.blackcoffer.com/telemedicine-what-patients-like-and-dislike-about-it/', 'https://insights.blackcoffer.com/how-we-forecast-future-technologies/', 'https://insights.blackcoffer.com/can-robots-tackle-late-life-loneliness/', 'https://insights.blackcoffer.com/embedding-care-robots-into-society-socio-technical-considerations/', 'https://insights.blackcoffer.com/management-challenges-for-future-digitalization-of-healthcare-services/', 'https://insights.blackcoffer.com/are-we-any-closer-to-preventing-a-nuclear-holocaust/', 'https://insights.blackcoffer.com/will-technology-eliminate-the-need-for-animal-testing-in-drug-development/', 'https://insights.blackcoffer.com/will-we-ever-understand-the-nature-of-consciousness/', 'https://insights.blackcoffer.com/will-we-ever-colonize-outer-space/', 'https://insights.blackcoffer.com/what-is-the-chance-homo-sapiens-will-survive-for-the-next-500-years/', 'https://insights.blackcoffer.com/why-does-your-business-need-a-chatbot/', 'https://insights.blackcoffer.com/how-you-lead-a-project-or-a-team-without-any-technical-expertise/', 'https://insights.blackcoffer.com/can-you-be-great-leader-without-technical-expertise/', 'https://insights.blackcoffer.com/how-does-artificial-intelligence-affect-the-environment/', 'https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes-2/', 'https://insights.blackcoffer.com/is-perfection-the-greatest-enemy-of-productivity/', 'https://insights.blackcoffer.com/global-financial-crisis-2008-causes-effects-and-its-solution/', 'https://insights.blackcoffer.com/gender-diversity-and-equality-in-the-tech-industry/', 'https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes/', 'https://insights.blackcoffer.com/how-small-business-can-survive-the-coronavirus-crisis/', 'https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors-and-food-stalls/', 'https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors/', 'https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-tourism-aviation-industries/', 'https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-sports-events-around-the-world/', 'https://insights.blackcoffer.com/changing-landscape-and-emerging-trends-in-the-indian-it-ites-industry/', 'https://insights.blackcoffer.com/online-gaming-adolescent-online-gaming-effects-demotivated-depression-musculoskeletal-and-psychosomatic-symptoms/', 'https://insights.blackcoffer.com/human-rights-outlook/', 'https://insights.blackcoffer.com/how-voice-search-makes-your-business-a-successful-business/', 'https://insights.blackcoffer.com/how-the-covid-19-crisis-is-redefining-jobs-and-services/', 'https://insights.blackcoffer.com/how-to-increase-social-media-engagement-for-marketers/', 'https://insights.blackcoffer.com/impacts-of-covid-19-on-streets-sides-food-stalls/', 'https://insights.blackcoffer.com/coronavirus-impact-on-energy-markets-2/', 'https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-5/', 'https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-4/', 'https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-2/', 'https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-3/', 'https://insights.blackcoffer.com/travel-and-tourism-outlook/', 'https://insights.blackcoffer.com/gaming-disorder-and-effects-of-gaming-on-health/', 'https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation/', 'https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation-2/', 'https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-office-space-and-co-working-industries/', 'https://insights.blackcoffer.com/contribution-of-handicrafts-visual-arts-literature-in-the-indian-economy/', 'https://insights.blackcoffer.com/how-covid-19-is-impacting-payment-preferences/', 'https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-2/']\n"
     ]
    }
   ],
   "source": [
    "# list of all the file id in input.xlsx file\n",
    "input = pd.read_excel('Input_data/Input.xlsx')\n",
    "url_id = input['URL_ID'].to_list()\n",
    "urls = input['URL'].to_list()\n",
    "print(len(url_id), url_id)\n",
    "print(len(urls), urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 15)\n",
      "['URL_ID', 'URL', 'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE', 'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH', 'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX', 'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT', 'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH']\n"
     ]
    }
   ],
   "source": [
    "# file 'Output Data Structure.xlsx' represents the structure for output\n",
    "output = pd.read_excel(r'Output_format/Output Data Structure.xlsx')\n",
    "print(output.shape)\n",
    "cols = list(output.columns)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# creating dataframe\n",
    "df = pd.DataFrame(columns=cols)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 ['blackassign0019.txt', 'blackassign0031.txt', 'blackassign0025.txt', 'blackassign0024.txt', 'blackassign0030.txt', 'blackassign0018.txt', 'blackassign0026.txt', 'blackassign0032.txt', 'blackassign0033.txt', 'blackassign0027.txt', 'blackassign0023.txt', 'blackassign0037.txt', 'blackassign0022.txt', 'blackassign0034.txt', 'blackassign0020.txt', 'blackassign0008.txt', 'blackassign0009.txt', 'blackassign0021.txt', 'blackassign0035.txt', 'blackassign0091.txt', 'blackassign0085.txt', 'blackassign0052.txt', 'blackassign0046.txt', 'blackassign0047.txt', 'blackassign0053.txt', 'blackassign0084.txt', 'blackassign0090.txt', 'blackassign0086.txt', 'blackassign0092.txt', 'blackassign0079.txt', 'blackassign0045.txt', 'blackassign0051.txt', 'blackassign0050.txt', 'blackassign0044.txt', 'blackassign0078.txt', 'blackassign0093.txt', 'blackassign0087.txt', 'blackassign0083.txt', 'blackassign0097.txt', 'blackassign0040.txt', 'blackassign0054.txt', 'blackassign0068.txt', 'blackassign0069.txt', 'blackassign0055.txt', 'blackassign0041.txt', 'blackassign0096.txt', 'blackassign0082.txt', 'blackassign0094.txt', 'blackassign0080.txt', 'blackassign0057.txt', 'blackassign0043.txt', 'blackassign0042.txt', 'blackassign0056.txt', 'blackassign0081.txt', 'blackassign0095.txt', 'blackassign0098.txt', 'blackassign0073.txt', 'blackassign0067.txt', 'blackassign0066.txt', 'blackassign0072.txt', 'blackassign0099.txt', 'blackassign0058.txt', 'blackassign0064.txt', 'blackassign0070.txt', 'blackassign0071.txt', 'blackassign0065.txt', 'blackassign0059.txt', 'blackassign0061.txt', 'blackassign0075.txt', 'blackassign0100.txt', 'blackassign0048.txt', 'blackassign0074.txt', 'blackassign0060.txt', 'blackassign0089.txt', 'blackassign0076.txt', 'blackassign0062.txt', 'blackassign0063.txt', 'blackassign0077.txt', 'blackassign0088.txt', 'blackassign0038.txt', 'blackassign0010.txt', 'blackassign0004.txt', 'blackassign0005.txt', 'blackassign0011.txt', 'blackassign0039.txt', 'blackassign0007.txt', 'blackassign0013.txt', 'blackassign0012.txt', 'blackassign0006.txt', 'blackassign0002.txt', 'blackassign0016.txt', 'blackassign0017.txt', 'blackassign0003.txt', 'blackassign0015.txt', 'blackassign0001.txt', 'blackassign0029.txt', 'blackassign0028.txt', 'blackassign0014.txt']\n"
     ]
    }
   ],
   "source": [
    "# accessing all files in folder 'Text_File'\n",
    "files = os.listdir('Text_File')\n",
    "print(len(files), files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15) \t Text_File/blackassign0001.txt \t completed....\n",
      "(2, 15) \t Text_File/blackassign0002.txt \t completed....\n",
      "(3, 15) \t Text_File/blackassign0003.txt \t completed....\n",
      "(4, 15) \t Text_File/blackassign0004.txt \t completed....\n",
      "(5, 15) \t Text_File/blackassign0005.txt \t completed....\n",
      "(6, 15) \t Text_File/blackassign0006.txt \t completed....\n",
      "(7, 15) \t Text_File/blackassign0007.txt \t completed....\n",
      "(8, 15) \t Text_File/blackassign0008.txt \t completed....\n",
      "(9, 15) \t Text_File/blackassign0009.txt \t completed....\n",
      "(10, 15) \t Text_File/blackassign0010.txt \t completed....\n",
      "(11, 15) \t Text_File/blackassign0011.txt \t completed....\n",
      "(12, 15) \t Text_File/blackassign0012.txt \t completed....\n",
      "(13, 15) \t Text_File/blackassign0013.txt \t completed....\n",
      "(14, 15) \t Text_File/blackassign0014.txt \t completed....\n",
      "(15, 15) \t Text_File/blackassign0015.txt \t completed....\n",
      "(16, 15) \t Text_File/blackassign0016.txt \t completed....\n",
      "(17, 15) \t Text_File/blackassign0017.txt \t completed....\n",
      "(18, 15) \t Text_File/blackassign0018.txt \t completed....\n",
      "(19, 15) \t Text_File/blackassign0019.txt \t completed....\n",
      "(20, 15) \t Text_File/blackassign0020.txt \t completed....\n",
      "(21, 15) \t Text_File/blackassign0021.txt \t completed....\n",
      "(22, 15) \t Text_File/blackassign0022.txt \t completed....\n",
      "(23, 15) \t Text_File/blackassign0023.txt \t completed....\n",
      "(24, 15) \t Text_File/blackassign0024.txt \t completed....\n",
      "(25, 15) \t Text_File/blackassign0025.txt \t completed....\n",
      "(26, 15) \t Text_File/blackassign0026.txt \t completed....\n",
      "(27, 15) \t Text_File/blackassign0027.txt \t completed....\n",
      "(28, 15) \t Text_File/blackassign0028.txt \t completed....\n",
      "(29, 15) \t Text_File/blackassign0029.txt \t completed....\n",
      "(30, 15) \t Text_File/blackassign0030.txt \t completed....\n",
      "(31, 15) \t Text_File/blackassign0031.txt \t completed....\n",
      "(32, 15) \t Text_File/blackassign0032.txt \t completed....\n",
      "(33, 15) \t Text_File/blackassign0033.txt \t completed....\n",
      "(34, 15) \t Text_File/blackassign0034.txt \t completed....\n",
      "(35, 15) \t Text_File/blackassign0035.txt \t completed....\n",
      "(37, 15) \t Text_File/blackassign0037.txt \t completed....\n",
      "(38, 15) \t Text_File/blackassign0038.txt \t completed....\n",
      "(39, 15) \t Text_File/blackassign0039.txt \t completed....\n",
      "(40, 15) \t Text_File/blackassign0040.txt \t completed....\n",
      "(41, 15) \t Text_File/blackassign0041.txt \t completed....\n",
      "(42, 15) \t Text_File/blackassign0042.txt \t completed....\n",
      "(43, 15) \t Text_File/blackassign0043.txt \t completed....\n",
      "(44, 15) \t Text_File/blackassign0044.txt \t completed....\n",
      "(45, 15) \t Text_File/blackassign0045.txt \t completed....\n",
      "(46, 15) \t Text_File/blackassign0046.txt \t completed....\n",
      "(47, 15) \t Text_File/blackassign0047.txt \t completed....\n",
      "(48, 15) \t Text_File/blackassign0048.txt \t completed....\n",
      "(50, 15) \t Text_File/blackassign0050.txt \t completed....\n",
      "(51, 15) \t Text_File/blackassign0051.txt \t completed....\n",
      "(52, 15) \t Text_File/blackassign0052.txt \t completed....\n",
      "(53, 15) \t Text_File/blackassign0053.txt \t completed....\n",
      "(54, 15) \t Text_File/blackassign0054.txt \t completed....\n",
      "(55, 15) \t Text_File/blackassign0055.txt \t completed....\n",
      "(56, 15) \t Text_File/blackassign0056.txt \t completed....\n",
      "(57, 15) \t Text_File/blackassign0057.txt \t completed....\n",
      "(58, 15) \t Text_File/blackassign0058.txt \t completed....\n",
      "(59, 15) \t Text_File/blackassign0059.txt \t completed....\n",
      "(60, 15) \t Text_File/blackassign0060.txt \t completed....\n",
      "(61, 15) \t Text_File/blackassign0061.txt \t completed....\n",
      "(62, 15) \t Text_File/blackassign0062.txt \t completed....\n",
      "(63, 15) \t Text_File/blackassign0063.txt \t completed....\n",
      "(64, 15) \t Text_File/blackassign0064.txt \t completed....\n",
      "(65, 15) \t Text_File/blackassign0065.txt \t completed....\n",
      "(66, 15) \t Text_File/blackassign0066.txt \t completed....\n",
      "(67, 15) \t Text_File/blackassign0067.txt \t completed....\n",
      "(68, 15) \t Text_File/blackassign0068.txt \t completed....\n",
      "(69, 15) \t Text_File/blackassign0069.txt \t completed....\n",
      "(70, 15) \t Text_File/blackassign0070.txt \t completed....\n",
      "(71, 15) \t Text_File/blackassign0071.txt \t completed....\n",
      "(72, 15) \t Text_File/blackassign0072.txt \t completed....\n",
      "(73, 15) \t Text_File/blackassign0073.txt \t completed....\n",
      "(74, 15) \t Text_File/blackassign0074.txt \t completed....\n",
      "(75, 15) \t Text_File/blackassign0075.txt \t completed....\n",
      "(76, 15) \t Text_File/blackassign0076.txt \t completed....\n",
      "(77, 15) \t Text_File/blackassign0077.txt \t completed....\n",
      "(78, 15) \t Text_File/blackassign0078.txt \t completed....\n",
      "(79, 15) \t Text_File/blackassign0079.txt \t completed....\n",
      "(80, 15) \t Text_File/blackassign0080.txt \t completed....\n",
      "(81, 15) \t Text_File/blackassign0081.txt \t completed....\n",
      "(82, 15) \t Text_File/blackassign0082.txt \t completed....\n",
      "(83, 15) \t Text_File/blackassign0083.txt \t completed....\n",
      "(84, 15) \t Text_File/blackassign0084.txt \t completed....\n",
      "(85, 15) \t Text_File/blackassign0085.txt \t completed....\n",
      "(86, 15) \t Text_File/blackassign0086.txt \t completed....\n",
      "(87, 15) \t Text_File/blackassign0087.txt \t completed....\n",
      "(88, 15) \t Text_File/blackassign0088.txt \t completed....\n",
      "(89, 15) \t Text_File/blackassign0089.txt \t completed....\n",
      "(90, 15) \t Text_File/blackassign0090.txt \t completed....\n",
      "(91, 15) \t Text_File/blackassign0091.txt \t completed....\n",
      "(92, 15) \t Text_File/blackassign0092.txt \t completed....\n",
      "(93, 15) \t Text_File/blackassign0093.txt \t completed....\n",
      "(94, 15) \t Text_File/blackassign0094.txt \t completed....\n",
      "(95, 15) \t Text_File/blackassign0095.txt \t completed....\n",
      "(96, 15) \t Text_File/blackassign0096.txt \t completed....\n",
      "(97, 15) \t Text_File/blackassign0097.txt \t completed....\n",
      "(98, 15) \t Text_File/blackassign0098.txt \t completed....\n",
      "(99, 15) \t Text_File/blackassign0099.txt \t completed....\n",
      "(100, 15) \t Text_File/blackassign0100.txt \t completed....\n"
     ]
    }
   ],
   "source": [
    "# calculating all parameters and adding into dataframe\n",
    "for id, link in zip(url_id, urls):\n",
    "    filename = str(id) + '.txt'\n",
    "    if filename not in files:\n",
    "        new_row = {\n",
    "            'URL_ID': id,\n",
    "            'URL': link,\n",
    "            'POSITIVE SCORE': -1,\n",
    "            'NEGATIVE SCORE': -1, \n",
    "            'POLARITY SCORE': -1, \n",
    "            'SUBJECTIVITY SCORE': -1, \n",
    "            'AVG SENTENCE LENGTH': -1, \n",
    "            'PERCENTAGE OF COMPLEX WORDS': -1, \n",
    "            'FOG INDEX': -1, \n",
    "            'AVG NUMBER OF WORDS PER SENTENCE': -1, \n",
    "            'COMPLEX WORD COUNT': -1, \n",
    "            'WORD COUNT': -1, \n",
    "            'SYLLABLE PER WORD': -1, \n",
    "            'PERSONAL PRONOUNS': -1, \n",
    "            'AVG WORD LENGTH':-1 \n",
    "        }\n",
    "        df.loc[len(df)] = new_row\n",
    "        continue\n",
    "\n",
    "    path = 'Text_File/' + filename\n",
    "    with open(path, 'r') as f:\n",
    "        content = f.readlines()\n",
    "        content[0] = content[0].rstrip('\\n')\n",
    "        text = ' '.join(content)\n",
    "\n",
    "    # tokenization\n",
    "    token_sent = sent_tokenize(text)\n",
    "    token_word = word_tokenize(text)\n",
    "\n",
    "    # removing stopwords\n",
    "    clean_word = clean(token_word)\n",
    "    \n",
    "    # calculating\n",
    "    score = sentimental_analysis(clean_word)\n",
    "    POSITIVE_SCORE = score[0]\n",
    "    NEGATIVE_SCORE = score[1]\n",
    "    POLARITY_SCORE = score[2]\n",
    "    SUBJECTIVITY_SCORE = score[3]\n",
    "\n",
    "    COMPLEX_WORDS = count_complex_words(clean_word)\n",
    "\n",
    "    results = readability(clean_word, token_sent, COMPLEX_WORDS)\n",
    "    AVERAGE_SENTENCE_LENGTH = results[0]\n",
    "    PERCENTAGE_OF_COMPLEX_WORDS = results[1]\n",
    "    FOG_INDEX = results[2]\n",
    "\n",
    "    AVERAGE_NUMBER_OF_WORDS_PER_SENTENCE = len(token_word) / len(token_sent)\n",
    "\n",
    "    WORD_COUNT = len(clean_word)\n",
    "\n",
    "    SYLLABLE_COUNT_PER_WORD = count_total_syllable(clean_word)\n",
    "\n",
    "    PERSONAL_PRONOUNS = count_personal_pronouns(text)\n",
    "\n",
    "    AVERAGE_WORD_LENGTH = calculate_avg_word_length(clean_word)\n",
    "\n",
    "    # adding into dataframe\n",
    "    new_row = {\n",
    "        'URL_ID': id,\n",
    "        'URL': link,\n",
    "        'POSITIVE SCORE': POSITIVE_SCORE,\n",
    "        'NEGATIVE SCORE': NEGATIVE_SCORE, \n",
    "        'POLARITY SCORE': POLARITY_SCORE, \n",
    "        'SUBJECTIVITY SCORE': SUBJECTIVITY_SCORE, \n",
    "        'AVG SENTENCE LENGTH': AVERAGE_SENTENCE_LENGTH, \n",
    "        'PERCENTAGE OF COMPLEX WORDS': PERCENTAGE_OF_COMPLEX_WORDS, \n",
    "        'FOG INDEX': FOG_INDEX, \n",
    "        'AVG NUMBER OF WORDS PER SENTENCE': AVERAGE_NUMBER_OF_WORDS_PER_SENTENCE, \n",
    "        'COMPLEX WORD COUNT': COMPLEX_WORDS, \n",
    "        'WORD COUNT': WORD_COUNT, \n",
    "        'SYLLABLE PER WORD': SYLLABLE_COUNT_PER_WORD, \n",
    "        'PERSONAL PRONOUNS': PERSONAL_PRONOUNS, \n",
    "        'AVG WORD LENGTH':AVERAGE_WORD_LENGTH \n",
    "    }\n",
    "\n",
    "    df.loc[len(df)] = new_row\n",
    "    print(df.shape, '\\t', path, '\\t', 'completed....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving output\n",
    "df.to_excel('Output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
